{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "system_prompt = \"\"\"You explain what code does\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Code Explanation**\\n\\nThe given code is a Python expression that uses the `yield` keyword to generate an iteration sequence. Here\\'s a breakdown of how it works:\\n\\n* `{...}`: An expression that evaluates to an iterable (like a list or generator).\\n* `(book.get(\"author\"))`: Each item in the iterable is an individual element that\\'s evaluated using the `get()` method.\\n* `for book in books`: This part specifies the iterable over which we\\'re applying the inner expression.\\n\\n**What it does**\\n\\nIn essence, this code says: \"For each book in the `books` collection:\\n\\n    1. Get the value of the \\'author\\' key from that book\\'s dictionary using `get()`.\\n    2. Yield (i.e., return) that author name as an individual element.\"\\n\\n**Why**\\n\\nThis code is often used to generate a sequence of authors extracted from multiple books. Here are a few reasons why someone might use this:\\n\\n* **Efficiency**: By yielding each author individually, we avoid unnecessary memory allocation for the entire sequence at once.\\n* **Flexibility**: This allows us to handle large or sparse collections without running out of memory.\\n* **Readability**: The syntax is concise and easy to understand.\\n\\n**Example Use Case**\\n\\nSuppose you have a list of book dictionaries (`books`):\\n\\n```python\\nbooks = [\\n    {\"id\": 1, \"title\": \"Book 1\", \"author\": \"John Smith\"},\\n    {\"id\": 2, \"title\": \"Book 2\", \"author\": \"Jane Doe\"},\\n    {\"id\": 3, \"title\": None, \"author\": None},  # Book with no author\\n]\\n```\\n\\nYou can generate a sequence of authors using this code:\\n\\n```python\\nfor author in yield from {book.get(\"author\") for book in books if book.get(\"author\"):\\n    print(author)\\n# Output:\\n# John Smith\\n# Jane Doe\\n```\\n\\nNote that the third element (`None`) won\\'t be included because the `if` clause excludes books with no author.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, without streaming\n",
    "\n",
    "# GPT\n",
    "response = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    ")\n",
    "result = response.choices[0].message.content\n",
    "result\n",
    "\n",
    "\n",
    "# Llama\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    ")\n",
    "result = response.choices[0].message.content\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**What the Code Does**\\n\\nThis line of code uses a few advanced Python features to extract specific values from an iterable. Here\\'s a breakdown:\\n\\n- `yield from`: This keyword is used to delegate the execution of the block of code after it to another iterable.\\n  \\n- `{}`: This represents a set comprehension, which creates a new iterator for the specified blocks and variables.\\n\\n- `\"author\"`: This string literal specifies the key in each iteration\\'s dictionary object (i.e., books) that should be chosen using `.get(\"author\")`.\\n\\n- `books`: This should be an iterable (such as list or tuple), where actual books are stored. This variable is not explicitly defined in the provided snippet, but it\\'s essential for understanding how this code works.\\n\\n**Why the Code Does What It Does**\\n\\nThe given line of code appears to fetch author names from a collection of book dictionaries. Here\\'s what it does step by step:\\n\\n1. `book.get(\"author\")`: This calls the \"get\" function on each dictionary in the iterable and returns the value associated with the key `\"author\"` (which is said to be missing for some books, hence using \".get\").\\n\\n2. `{...}`: Any non-zero values returned from `book.get(\"author\")` are stored as elements of this set comprehension\\'s iterator.\\n\\n3. `yield from {...}`: This takes an iterator created in the previous step and delegates the iteration over it to another iterable (in this case, also an iterator - because we\\'re dealing with dict objects), where each yielded element becomes a single value of the resulting set comprehension.\\n\\n4. The dictionary of all these names is collected as one of the key values generated through execution of a block of code.\\n\\n\\nIn essence, the line of code returns `book.get(\"author\")` for every book `\"book\"` in `books`, provided `\"author\"` exists, then those results are put in an iterable and returned. The exact output depends on what that list looks like.\\n\\nSo, when to use this: This technique can be helpful if you know you\\'re going to process some data (especially a potentially expensive operation like accessing elements of dictionary), and you need to avoid loading the whole list into memory simultaneously.\\n\\nHere is example:\\n\\n\\n```python\\nbooks = [\\n    {\"author\": \"Author 1\", \"title\": \"Title 1\"},\\n    {\"title\": \"Title 2\"},\\n    {\"author\": \"Author 3\"}\\n]\\nfor author in yield from {book.get(\"author\") for book in books if book.get(\"author\")}:\\n    print(f\"Found Author: {author}\")\\n```'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "# # GPT\n",
    "# stream = openai.chat.completions.create(\n",
    "#     model=\"gpt-4.1-mini\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": system_prompt},\n",
    "#         {\"role\": \"user\", \"content\": user_prompt}\n",
    "#       ],\n",
    "#     stream=True,\n",
    "# )\n",
    "\n",
    "# response = \"\"\n",
    "# for chunk in stream:\n",
    "#     response += chunk.choices[0].delta.content or ''\n",
    "\n",
    "# response\n",
    "\n",
    "\n",
    "# # Llama\n",
    "stream = ollama.chat.completions.create(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "response = \"\"\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d291c-2acf-4b28-ad80-1f0f00a722ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1667cf2-4819-428c-8aab-496eb631df86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
